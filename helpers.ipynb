{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef11c2-f2d3-46da-9784-e79e56e727a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_folders(base_path, model, device):\n",
    "    evaluate = lambda case_path: newmodel.evaluate_case(model, case_path, device)\n",
    "    evaluations = px.recurse(\n",
    "        base_path,\n",
    "        px.is_trainable,\n",
    "        case_in=\"  [bold black]{case}.[/bold black] Evaluating...\",\n",
    "        case_out=\"  ...completed.\",\n",
    "    )(evaluate)\n",
    "    print(\"Mean liver score:\", sum(item[\"liver\"] for item in evaluations.values()) / len(evaluations))\n",
    "    print(\"Mean tumor score:\", sum(item[\"tumor\"] for item in evaluations.values()) / len(evaluations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7068a96-b0a3-439d-8fea-e30b329bd000",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup BBE9 #################################################################\n",
    "model_name = \"BBE9_360.pth\"\n",
    "base_path = \"/content/drive/MyDrive/COLAB\"\n",
    "drive_mount=\"/content/drive\"\n",
    "################################################################################\n",
    "\n",
    "%cd /content/liver\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "import newmodel\n",
    "import utils.path_explorer as px\n",
    "from newmodel.models import UNet\n",
    "from utils.namespace import Namespace\n",
    "\n",
    "env_opts = Namespace(\n",
    "    dataset_path = Path(\"/content/dataset\"),\n",
    "    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "    drive_folder = Path(drive_mount) / \"MyDrive\" / \"COLAB\",\n",
    "    models_path = Path(drive_mount) / \"MyDrive\" / \"saved_models\",\n",
    ")\n",
    "\n",
    "run_opts = Namespace(\n",
    "    batch_size=5,\n",
    "    buffer_size=100,\n",
    "    lr=1e-3 / 20,\n",
    "    momentum = 0.9,\n",
    "    resume=False,\n",
    "    setup_id = \"BBE9\",\n",
    ")\n",
    "\n",
    "net_opts = Namespace(\n",
    "    channels=[4, 48, 64, 80, 96],\n",
    "    down_normalization=\"instance\",\n",
    "    up_dropout=\"drop\",\n",
    ")\n",
    "\n",
    "opts = Namespace(env_opts, run_opts, net_opts)\n",
    "\n",
    "model = UNet(**opts)\n",
    "model.to(device=opts.device)\n",
    "model.load_state_dict(torch.load(opts.models_path / model_name, map_location=opts.device))\n",
    "\n",
    "evaluate_all_folders(Path(base_path), model, opts.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b15bbd2-23dd-417d-859f-c46cf7e84843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-06 11:04:28--  https://drive.google.com/drive/folders/0B8279de5ddn5RTM1cUZWYW1JQXM?resourcekey=0-BPxXCfTIxz8PHLyhyubz1g&usp=sharing&export=download&confirm=t&id=0B8279de5ddn5RTM1cUZWYW1JQXM\n",
      "Resolving drive.google.com (drive.google.com)... 142.250.184.46, 2a00:1450:4002:404::200e\n",
      "Connecting to drive.google.com (drive.google.com)|142.250.184.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘/content/down.zip’\n",
      "\n",
      "/content/down.zip       [  <=>               ] 322.80K  1021KB/s    in 0.3s    \n",
      "\n",
      "2022-08-06 11:04:30 (1021 KB/s) - ‘/content/down.zip’ saved [330544]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How to download files\n",
    "# https://drive.google.com/file/d/1oohOGFr-yK9f1AZEwzkzG13-eEBQwn75/view?usp=sharing\n",
    "# file_download_link = \"https://docs.google.com/uc?export=download&confirm=t&id=0B8279de5ddn5RTM1cUZWYW1JQXM\"\n",
    "file_download_link = \"https://drive.google.com/drive/folders/0B8279de5ddn5RTM1cUZWYW1JQXM?resourcekey=0-BPxXCfTIxz8PHLyhyubz1g&usp=sharing&export=download&confirm=t&id=0B8279de5ddn5RTM1cUZWYW1JQXM\"\n",
    "!wget -O /content/down.zip --no-check-certificate \"$file_download_link\"\n",
    "# https://drive.google.com/drive/folders/0B8279de5ddn5RTM1cUZWYW1JQXM?resourcekey=0-BPxXCfTIxz8PHLyhyubz1g&usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ab909-405b-4417-b23f-7eeedba8db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From trainbundle back to registered images\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import dataset.ndarray as nd\n",
    "\n",
    "source_path = Path(\"\")\n",
    "target_path = Path(\"\")\n",
    "case = \"\"\n",
    "case_path = source_path / case\n",
    "bundle = nd.load_niftidata(case_path)\n",
    "affine, bottom, top, height = np.eye(4), 0, bundle.shape[3], bundle.shape[3]\n",
    "regs = {phase: bundle[n] for n, phase in enumerate([\"b\", \"a\", \"v\", \"t\"])}\n",
    "nd.save_registereds(regs, target_path / case, affine, bottom, top, height)\n",
    "nd.save_niftiimage(target_path / case / \"segmentation.nii.gz\", bundle[4], affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "026d8439-1d49-4550-8db4-8a339ed9c5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig (512, 512, 219) [[  -0.72070312    0.            0.          187.5       ]\n",
      " [  -0.            0.72070312    0.         -341.77929688]\n",
      " [   0.           -0.            3.         -128.        ]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "reg (512, 512, 219) [[  -0.72070312    0.            0.          187.5       ]\n",
      " [  -0.            0.72070312    0.         -341.77929688]\n",
      " [   0.           -0.            3.         -128.        ]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "{'affine': array([[  -0.72070312,    0.        ,    0.        ,  187.5       ],\n",
      "       [  -0.        ,    0.72070312,    0.        , -341.77929688],\n",
      "       [   0.        ,   -0.        ,    3.        , -128.        ],\n",
      "       [   0.        ,    0.        ,    0.        ,    1.        ]]), 'bottom': 1, 'top': 139, 'height': 219}\n",
      "segm (512, 512, 219) [[  -0.72070312    0.            0.          187.5       ]\n",
      " [  -0.            0.72070312    0.         -341.77929688]\n",
      " [   0.           -0.            3.         -128.        ]\n",
      " [   0.            0.            0.            1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Flip segmentation\n",
    "from pathlib import Path\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dataset.ndarray\n",
    "\n",
    "case_path = Path(\"/mnt/chromeos/GoogleDrive/MyDrive/COLAB\") / \"Hum249\"\n",
    "orig, orig_aff = dataset.ndarray.load_original(case_path, \"v\")\n",
    "print(\"orig\", orig.shape, orig_aff)\n",
    "reg, reg_aff = dataset.ndarray.load_registered(case_path, \"v\")\n",
    "print(\"reg\", reg.shape, reg_aff)\n",
    "registration_data = pickle.load(open(case_path / \"registration_data.pickle\", \"rb\"))\n",
    "print(registration_data)\n",
    "segm_image = nibabel.load(case_path / f\"segmentation_from_corrected.nii.gz\")\n",
    "segm = np.array(segm_image.dataobj)\n",
    "segm_aff = segm_image.affine\n",
    "print(\"segm\", segm.shape, segm_aff)\n",
    "\n",
    "new_image = nibabel.Nifti1Image(np.flip(segm, axis=1), reg_aff)\n",
    "# nibabel.save(new_image, case_path / f\"segmentation_from_corrected.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019a35a2-5f2b-4402-a583-11a0e10b78d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig (512, 512, 86) [[  -0.80078125    0.            0.          220.        ]\n",
      " [  -0.            0.80078125    0.         -351.19921875]\n",
      " [   0.           -0.            3.         -193.        ]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "reg (512, 512, 86) [[  -0.80078125    0.            0.          220.        ]\n",
      " [  -0.            0.80078125    0.         -351.19921875]\n",
      " [   0.           -0.            3.         -193.        ]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "segm (512, 512, 85) [[  -0.80078125    0.            0.          220.        ]\n",
      " [  -0.            0.80078125    0.         -351.19921875]\n",
      " [   0.           -0.            3.         -193.        ]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "{'affine': array([[  -0.80078125,    0.        ,    0.        ,  220.        ],\n",
      "       [  -0.        ,    0.80078125,    0.        , -351.19921875],\n",
      "       [   0.        ,   -0.        ,    3.        , -193.        ],\n",
      "       [   0.        ,    0.        ,    0.        ,    1.        ]]), 'bottom': 0, 'top': 86, 'height': 86}\n"
     ]
    }
   ],
   "source": [
    "# Fix segmentation\n",
    "from pathlib import Path\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dataset.ndarray\n",
    "\n",
    "case_path = Path(\"/mnt/chromeos/GoogleDrive/MyDrive/COLAB\") / \"Hum263\"\n",
    "orig, orig_aff = dataset.ndarray.load_original(case_path, \"v\")\n",
    "print(\"orig\", orig.shape, orig_aff)\n",
    "reg, reg_aff = dataset.ndarray.load_registered(case_path, \"v\")\n",
    "print(\"reg\", reg.shape, reg_aff)\n",
    "segm_image = nibabel.load(case_path / f\"segmentation_from_drive.nii.gz\")\n",
    "segm = np.array(segm_image.dataobj)\n",
    "segm_aff = segm_image.affine\n",
    "print(\"segm\", segm.shape, segm_aff)\n",
    "\n",
    "registration_data = pickle.load(open(case_path / \"registration_data.pickle\", \"rb\"))\n",
    "print(registration_data)\n",
    "new_segm = np.zeros_like(reg)\n",
    "a = registration_data[\"bottom\"]\n",
    "new_segm[..., a:a+segm.shape[2]] = segm\n",
    "new_image = nibabel.Nifti1Image(new_segm, reg_aff)\n",
    "nibabel.save(new_image, case_path / f\"segmentation.nii.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
